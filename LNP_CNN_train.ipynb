{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN for t=1 to t=20\n",
    "Taking first three convolutional and pooling layers (first three blocks) of VGG16. In the final block extract the final convolutional layer and add on top of the network the following layers:\n",
    "1. Batch normalization\n",
    "2. Global average pooling\n",
    "3. Latent vector\n",
    "4. Batch normalization (size 32 - this is the feature vector for use in the time-series modelling)\n",
    "5. RELU activation\n",
    "6. Final dense layer of size 1 (with a sigmoid activation for classification mode and no activation when in prediction/regression mode).\n",
    "\n",
    "\n",
    "### Modelling info\n",
    "5 fold cross-validation on training data. Binary cross-entropy loss for classification and MSE loss for the regressor along with the Adam optimizer (with a learning rate of 0.001). Batch size of 32. Training for 50 epochs with the base model frozen. 50 epochs was sufficient for convergence. Unfreezing the base after and training for more epochs did not lower the validation loss, so here the base is kept frozen. 90 degree rotations and mirroring were used to augment the training data to 8 times its size. Augmentation was also used on the validation data (and will also be used in the end, in later notebooks, on the test data). Save best weights as go along and best model at the end."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'2.2.4'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "import keras\n",
    "keras.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import re\n",
    "import glob\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.preprocessing import image\n",
    "from keras.applications.vgg16 import preprocess_input\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense, Flatten, Activation, BatchNormalization, GlobalAveragePooling2D\n",
    "from keras.optimizers import RMSprop, Adam\n",
    "from keras import backend as K\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.utils import class_weight\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def atoi(text):\n",
    "    return int(text) if text.isdigit() else text\n",
    "\n",
    "def natural_keys(text):\n",
    "    return [atoi(c) for c in re.split('(\\d+)', text)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_history(model_history, model_name, fit_method):\n",
    "    fig = plt.figure(figsize=(8,5), facecolor='w')\n",
    "    ax = fig.add_subplot(111)\n",
    "    ax.plot(model_history.history['loss'])\n",
    "    ax.plot(model_history.history['val_loss'])\n",
    "    ax.set(title=model_name + ': Model loss', ylabel='Loss', xlabel='Epoch')\n",
    "    ax.legend(['Train', 'Test'], loc='upper right')\n",
    "    plt.show()\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_image(path, stats, rescale_method):\n",
    "    img = np.load(path)\n",
    "    img = img.astype('float32')\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count"