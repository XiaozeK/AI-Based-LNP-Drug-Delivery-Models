{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating datasets for time-series models (t=1 to t=20)\n",
    "* based upon the trained CNNs for feature extraction \n",
    "* both classification and regression mode and five cross-validation folds\n",
    "* also plotting here some time-series feature vectors "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'2.2.4'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "import keras\n",
    "keras.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import re\n",
    "import glob\n",
    "from keras.models import load_model\n",
    "from keras.models import Model\n",
    "from keras import backend as K\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def atoi(text):\n",
    "    return int(text) if text.isdigit() else text\n",
    "\n",
    "def natural_keys(text):\n",
    "    return [atoi(c) for c in re.split('(\\d+)', text)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_image(path, stats, rescale_method):\n",
    "    img = np.load(path)\n",
    "    img = img.astype('float32')\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_gfp(path, stats, rescale_method, fit_method, gfp_thresh):\n",
    "    gfp = np.load(path)\n",
    "    if fit_method == 'classify':\n",
    "        if gfp <= gfp_thresh:\n",
    "            res = 0.\n",
    "        else:\n",
    "            res = 1.\n",
    "    if fit_method == 'regress':\n",
    "        if rescale_method == 'log':\n",
    "            res = np.log(gfp)\n",
    "        if rescale_method == 'log_center':\n",
    "            res = np.log(gfp) - np.log(stats[2])\n",
    "        if rescale_method == 'normalize':\n",
    "            res = (gfp - stats[0])/(stats[1] - stats[0])\n",
    "        if rescale_method == 'standardize':\n",
    "            res = (gfp - stats[2])/stats[3]\n",
    "        if rescale_method == 'log_normalize':\n",
    "            res = (np.log(gfp) - np.log(stats[0]))/(np.log(stats[1]) - np.log(stats[0]))\n",
    "        if rescale_method == 'log_standardize':\n",
    "            res = (np.log(gfp) - np.log(stats[2]))/np.log(stats[3])\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rotate90xDegrees(img):\n",
    "    ret =[]\n",
    "    rows, cols = img.shape\n",
    "    for i in range(1,4):\n",
    "        M = cv2.getRotationMatrix2D((cols/2,rows/2),i*90,1)\n",
    "        ret.append(cv2.warpAffine(img,M,(cols,rows)))\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def augment_image(img, aug_no):\n",
    "    img_new = np.zeros((img.shape)).astype('float32')\n",
    "    rows, cols, chans = img.shape\n",
    "    for i in range(chans):\n",
    "        if aug_no == 0:\n",
    "            img_new[:, :, i] = img[:, :, i]\n",
    "        if aug_no == 1:\n",
    "            img_new[:, :, i] = np.flipud(img[:, :, i])\n",
    "        if aug_no == 2:\n",
    "            img_new[:, :, i] = np.fliplr(img[:, :, i])\n",
    "        if aug_no == 3:\n",
    "            ud = np.flipud(img[:, :, i])\n",
    "            img_new[:, :, i] = np.fliplr(ud)\n",
    "        if aug_no == 4:\n",
    "            img_new[:, :, i] = rotate90xDegrees(img[:, :, i])[0]\n",
    "        if aug_no == 5:\n",
    "            ud = np.flipud(img[:, :, i])\n",
    "            img_new[:, :, i] = rotate90xDegrees(ud)[0]\n",
    "        if aug_no == 6:\n",
    "            lr = np.fliplr(img[:, :, i])\n",
    "            img_new[:, :, i] = rotate90xDegrees(lr)[0]\n",
    "        if aug_no == 7:\n",
    "            ud = np.flipud(img[:, :, i])\n",
    "            udlr = np.fliplr(ud)\n",
    "            img_new[:, :, i] = rotate90xDegrees(udlr)[0]\n",
    "    \n",
    "    return img_new"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "fold = 'fold5'\n",
    "\n",
    "wells = ['C04', 'C05', 'E03', 'E04', 'E05', 'G03', 'G04', 'G05']\n",
    "n_wells = len(wells) \n",
    "\n",
    "tpoints = 'T0001'\n",
    "for i in range(2, 10):\n",
    "    tpoints = np.append(tpoints, 'T000' + str(i))\n",
    "for i in range(10, 21):\n",
    "    tpoints = np.append(tpoints, 'T00' + str(i))\n",
    "n_time = len(tpoints)\n",
    "\n",
    "fit_method = 'regress' # 'classify' or 'regress'\n",
    "# previous explorations showed the following two rescaling methods to be the most appropriate\n",
    "cell_rescale_method = 'standardize'\n",
    "gfp_rescale_method = 'log_center'\n",
    "cell_stats = np.load('/scratch-shared/phil/LNP/LNP_data_09/cell_stats.npy')\n",
    "gfp_stats = np.load('/scratch-shared/phil/LNP/LNP_data_09/gfp_stats.npy')\n",
    "\n",
    "latent_dim = 32\n",
    "\n",
    "CNN = load_model('/scratch-shared/phil/LNP/LNP_data_09/CNN_' + fit_method + '_' + fold + '.h5')\n",
    "encoder = Model(inputs=CNN.get_layer('input_1').input, outputs=CNN.get_layer('latent_vector').output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 192, 192, 3)       0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 192, 192, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 192, 192, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 96, 96, 64)        0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 96, 96, 128)       73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 96, 96, 128)       147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 48, 48, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 48, 48, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 48, 48, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 48, 48, 256)       590080    \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 48, 48, 256)       1024      \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d_1 ( (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 32)                8224      \n",
      "_________________________________________________________________\n",
      "latent_vector (BatchNormaliz (None, 32)                128       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 1,744,897\n",
      "Trainable params: 1,744,321\n",
      "Non-trainable params: 576\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "CNN.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_ts(pred_cell, encoder):\n",
    "    for ii, image_path in enumerate(pred_cell):\n",
    "        for aug_num in range(8):\n",
    "            img = get_image(image_path, stats=cell_stats, rescale_method=cell_rescale_method)\n",
    "            img = augment_image(img, aug_no=aug_num)\n",
    "            img = np.reshape(img, (1, 192, 192, 3))\n",
    "            pred = np.ndarray.flatten(encoder.predict(img))\n",
    "            if ii == 0 and aug_num == 0:\n",
    "                pred_pred = pred\n",
    "            else:\n",
    "                pred_pred = np.vstack((pred_pred, pred))\n",
    "            \n",
    "    return pred_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make training time-series data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_cell_dir = '/scratch-shared/phil/LNP/LNP_data_09/images_train'\n",
    "train_gfp_dir = '/scratch-shared/phil/LNP/LNP_data_09/gfp_train'\n",
    "\n",
    "cell_ids = []\n",
    "cell_gfp = []\n",
    "\n",
    "all_cell = glob.glob(train_cell_dir + '/' '*')\n",
    "all_cell = sorted(all_cell, key = natural_keys)\n",
    "all_gfp = []\n",
    "cell_well_tpoint = [] # well id and tpoint for each cell in each time point\n",
    "for cell in all_cell:\n",
    "    s0 = cell.split('train/')\n",
    "    s1 = s0[1].split('_')\n",
    "    f = glob.glob(train_gfp_dir + '/*' + s1[1] + '_' + s1[2] + '_T0072_cell_' + s1[5])\n",
    "    all_gfp.extend(f)\n",
    "    cell_well_tpoint.append([s1[1], s1[3]])\n",
    "\n",
    "t_index = 0\n",
    "for tpoint in tpoints:\n",
    "    pred_index = [i for i, index in enumerate(cell_well_tpoint) if index[1] == tpoint]\n",
    "    pred_cell = [all_cell[i] for i in pred_index]\n",
    "    pred_gfp = [all_gfp[i] for i in pred_index]\n",
    "    res = predict_ts(pred_cell, encoder)\n",
    "\n",
    "    if t_index == 0:\n",
    "        res_tpoints = np.zeros((len(res), n_time, latent_dim)) \n",
    "\n",
    "    res_tpoints[:, t_index, :] = res\n",
    "    t_index += 1\n",
    "\n",
    "pred_y = []\n",
    "for ii, path in enumerate(pred_gfp):\n",
    "    target = get_gfp(path, stats=gfp_stats, rescale_method=gfp_rescale_method,\n",
    "                     fit_method=fit_method, gfp_thresh=gfp_stats[4])\n",
    "    pred_y.append(target)\n",
    "cell_ids = cell_ids + [ele for ele in pred_cell for i in range(8)] # 8 for 8x augmentations\n",
    "cell_gfp = cell_gfp + [ele for ele in pred_y for i in range(8)]\n",
    "\n",
    "np.save('/scratch-shared/phil/LNP/LNP_data_09/train_cell_ids_' + fit_method  + '_' + fold + '.npy', cell_ids)\n",
    "np.save('/scratch-shared/phil/LNP/LNP_data_09/train_cell_gfp_' + fit_method  + '_' + fold + '.npy', cell_gfp)\n",
    "\n",
    "np.save('/scratch-shared/phil/LNP/LNP_data_09/train_ts_' + fit_method  + '_' + fold + '.npy', res_tpoints)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make testing time-series data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_cell_dir = '/scratch-shared/phil/LNP/LNP_data_09/images_test'\n",
    "test_gfp_dir = '/scratch-shared/phil/LNP/LNP_data_09/gfp_test'\n",
    "\n",
    "cell_ids = []\n",
    "cell_gfp = []\n",
    "\n",
    "all_cell = glob.glob(test_cell_dir + '/' '*')\n",
    "all_cell = sorted(all_cell, key = natural_keys)\n",
    "all_gfp = []\n",
    "cell_well_tpoint = [] # well id and tpoint for each cell in each time point\n",
    "for cell in all_cell:\n",
    "    s0 = cell.split('test/')\n",
    "    s1 = s0[1].split('_')\n",
    "    f = glob.glob(test_gfp_dir + '/' + s1[0] + '_' + s1[1] + '_T0072_cell_' + s1[4])\n",
    "    all_gfp.extend(f)\n",
    "    cell_well_tpoint.append([s1[0], s1[2]])\n",
    "\n",
    "t_index = 0\n",
    "for tpoint in tpoints:\n",
    "    pred_index = [i for i, index in enumerate(cell_well_tpoint) if index[1] == tpoint]\n",
    "    pred_cell = [all_cell[i] for i in pred_index]\n",
    "    pred_gfp = [all_gfp[i] for i in pred_index]\n",
    "    res = predict_ts(pred_cell, encoder)\n",
    "\n",
    "    if t_index == 0:\n",
    "        res_tpoints = np.zeros((len(res), n_time, latent_dim)) \n",
    "\n",
    "    res_tpoints[:, t_index, :] = res\n",
    "    t_index += 1\n",
    "\n",
    "pred_y = []\n",
    "for ii, path in enumerate(pred_gfp):\n",
    "    target = get_gfp(path, stats=gfp_stats, rescale_method=gfp_rescale_method,\n",
    "                     fit_method=fit_method, gfp_thresh=gfp_stats[4])\n",
    "    pred_y.append(target)\n",
    "cell_ids = cell_ids + [ele for ele in pred_cell for i in range(8)] # 8 for 8x augmentations\n",
    "cell_gfp = cell_gfp + [ele for ele in pred_y for i in range(8)]\n",
    "\n",
    "np.save('/scratch-shared/phil/LNP/LNP_data_09/test_cell_ids_' + fit_method + '_' + fold + '.npy', cell_ids)\n",
    "np.save('/scratch-shared/phil/LNP/LNP_data_09/test_cell_gfp_' + fit_method + '_' + fold + '.npy', cell_gfp)\n",
    "\n",
    "np.save('/scratch-shared/phil/LNP/LNP_data_09/test_ts_' + fit_method + '_' + fold + '.npy', res_tpoints)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## plot of time series feature vectors for eight augmentations of one cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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