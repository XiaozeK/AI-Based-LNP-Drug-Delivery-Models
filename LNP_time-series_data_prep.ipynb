{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating datasets for time-series models (t=1 to t=20)\n",
    "* based upon the trained CNNs for feature extraction \n",
    "* both classification and regression mode and five cross-validation folds\n",
    "* also plotting here some time-series feature vectors "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'2.2.4'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "import keras\n",
    "keras.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import re\n",
    "import glob\n",
    "from keras.models import load_model\n",
    "from keras.models import Model\n",
    "from keras import backend as K\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def atoi(text):\n",
    "    return int(text) if text.isdigit() else text\n",
    "\n",
    "def natural_keys(text):\n",
    "    return [atoi(c) for c in re.split('(\\d+)', text)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_image(path, stats, rescale_method):\n",
    "    img = np.load(path)\n",
    "    img = img.astype('float32')\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_gfp(path, stats, rescale_method, fit_method, gfp_thresh):\n",
    "    gfp = np.load(path)\n",
    "    if fit_method == 'classify':\n",
    "        if gfp <= gfp_thresh:\n",
    "            res = 0.\n",
    "        else:\n",
    "            res = 1.\n",
    "    if fit_method == 'regress':\n",
    "        if rescale_method == 'log':\n",
    "            res = np.log(gfp)\n",
    "        if rescale_method == 'log_center':\n",
    "            res = np.log(gfp) - np.log(stats[2])\n",
    "        if rescale_method == 'normalize':\n",
    "            res = (gfp - stats[0])/(stats[1] - stats[0])\n",
    "        if rescale_method == 'standardize':\n",
    "            res = (gfp - stats[2])/stats[3]\n",
    "        if rescale_method == 'log_normalize':\n",
    "            res = (np.log(gfp) - np.log(stats[0]))/(np.log(stats[1]) - np.log(stats[0]))\n",
    "        if rescale_method == 'log_standardize':\n",
    "            res = (np.log(gfp) - np.log(stats[2]))/np.log(stats[3])\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rotate90xDegrees(img):\n",
    "    ret =[]\n",
    "    rows, cols = img.shape\n",
    "    for i in range(1,4):\n",
    "        M = cv2.getRotationMatrix2D((cols/2,rows/2),i*90,1)\n",
    "        ret.append(cv2.warpAffine(img,M,(cols,rows)))\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def augment_image(img, aug_no):\n",
    "    img_new = np.zeros((img.shape)).astype('float32')\n",
    "    rows, cols, chans = img.shape\n",
    "    for i in range(chans):\n",
    "        if aug_no == 0:\n",
    "            img_new[:, :, i] = img[:, :, i]\n",
    "        if aug_no == 1:\n",
    "            img_new[:, :, i] = np.flipud(img[:, :, i])\n",
    "        if aug_no == 2:\n",
    "            img_new[:, :, i] = np.fliplr(img[:, :, i])\n",
    "        if aug_no == 3:\n",
    "            ud = np.flipud(img[:, :, i])\n",
    "            img_new[:, :, i] = np.fliplr(ud)\n",
    "        if aug_no == 4:\n",
    "            img_new[:, :, i] = rotate90xDegrees(img[:, :, i])[0]\n",
    "        if aug_no == 5:\n",
    "            ud = np.flipud(img[:, :, i])\n",
    "            img_new[:, :, i] = rotate90xDegrees(ud)[0]\n",
    "        if aug_no == 6:\n",
    "            lr = np.fliplr(img[:, :, i])\n",
    "            img_new[:, :, i] = rotate90xDegrees(lr)[0]\n",
    "        if aug_no == 7:\n",
    "            ud = np.flipud(img[:, :, i])\n",
    "            udlr = np.fliplr(ud)\n",
    "            img_new[:, :, i] = rotate90xDegrees(udlr)[0]\n",
    "    \n",
    "    return img_new"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "fold = 'fold5'\n",
    "\n",
    "wells = ['C04', 'C05', 'E03', 'E04', 'E05', 'G03', 'G04', 'G05']\n",
    "n_wells = len(wells) \n",
    "\n",
    "tpoints = 'T0001'\n",
    "for i in range(2, 10):\n",
    "    tpoints = np.append(tpoints, 'T000' + str(i))\n",
    "for i in range(10, 21):\n",
    "    tpoints = np.append(tpoints, 'T00' + str(i))\n",
    "n_time = len(tpoints)\n",
    "\n",
    "fit_method = 'regress' # 'classify' or 'regress'\n",
    "# previous explorations showed the following two rescaling methods to be the most appropriate\n",
    "cell_rescale_method = 'standardize'\n",
    "gfp_rescale_method = 'log_center'\n",
    "cell_stats = np.load('/scratch-shared/phil/LNP/LNP_data_09/cell_stats.npy')\n",
    "gfp_stats = np.load('/scratch-shared/phil/LNP/LNP_data_09/gfp_stats.npy')\n",
    "\n",
    "latent_dim = 32\n",
    "\n",
    "CNN = load_model('/scratch-shared/phil/LNP/LNP_data_09/CNN_' + fit_method + '_' + fold + '.h5')\n",
    "encoder = Model(inputs=CNN.get_layer('input_1').input, outputs=CNN.get_layer('latent_vector').output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 192, 192, 3)       0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 192, 192, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 192, 192, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 96, 96, 64)        0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 96, 96, 128)       73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 96, 96, 128)       147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 48, 48, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 48, 48, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 48, 48, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 48, 48, 256)       590080    \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 48, 48, 256)       1024      \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d_1 ( (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 32)                8224      \n",
      "_________________________________________________________________\n",
      "latent_vector (BatchNormaliz (None, 32)                128       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 1,744,897\n",
      "Trainable params: 1,744,321\n",
      "Non-trainable params: 576\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "CNN.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_ts(pred_cell, encoder):\n",
    "    for ii, image_path in enumerate(pred_cell):\n",
    "        for aug_num in range(8):\n",
    "            img = get_image(image_path, stats=cell_stats, rescale_method=cell_rescale_method)\n",
    "            img = augment_image(img, aug_no=aug_num)\n",
    "            img = np.reshape(img, (1, 192, 192, 3))\n",
    "            pred = np.ndarray.flatten(encoder.predict(img))\n",
    "            if ii == 0 and aug_num == 0:\n",
    "                pred_pred = pred\n",
    "            else:\n",
    "                pred_pred = np.vstack((pred_pred, pred))\n",
    "            \n",
    "    return pred_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make training time-series data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_cell_dir = '/scratch-shared/phil/LNP/LNP_data_09/images_train'\n",
    "train_gfp_dir = '/scratch-shared/phil/LNP/LNP_data_09/gfp_train'\n",
    "\n",
    "cell_ids = []\n",
    "cell_gfp = []\n",
    "\n",
    "all_cell = glob.glob(train_cell_dir + '/' '*')\n",
    "all_cell = sorted(all_cell, key = natural_keys)\n",
    "all_gfp = []\n",
    "cell_well_tpoint = [] # well id and tpoint for each cell in each time point\n",
    "for cell in all_cell:\n",
    "    s0 = cell.split('train/')\n",
    "    s1 = s0[1].split('_')\n",
    "    f = glob.glob(train_gfp_dir + '/*' + s1[1] + '_' + s1[2] + '_T0072_cell_' + s1[5])\n",
    "    all_gfp.extend(f)\n",
    "    cell_well_tpoint.append([s1[1], s1[3]])\n",
    "\n",
    "t_index = 0\n",
    "for tpoint in tpoints:\n",
    "    pred_index = [i for i, index in enumerate(cell_well_tpoint) if index[1] == tpoint]\n",
    "    pred_cell = [all_cell[i] for i in pred_index]\n",
    "    pred_gfp = [all_gfp[i] for i in pred_index]\n"